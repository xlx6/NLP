{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a0e3ff",
   "metadata": {},
   "source": [
    "## Generate Request Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb25f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "system_prompt = \"\"\"You are a professional evaluator of language model outputs. Your task is to score a model's response against a reference answer, based on the given instruction and input. Rate the response on a **0–5 scale** for each of the following:\n",
    "\n",
    "1. **Correctness**: Is the information accurate and logical?\n",
    "2. **Completeness**: Does it cover all required points?\n",
    "3. **Relevance**: Is all content relevant to the task?\n",
    "4. **Fluency**: Is the language natural, grammatically correct, and well-structured?\n",
    "\n",
    "Return only the result in **strict JSON** format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"Correctness\": ?,\n",
    "  \"Completeness\": ?,\n",
    "  \"Relevance\": ?,\n",
    "  \"Fluency\": ?\n",
    "}}\n",
    "```\"\"\"\n",
    "template_user = \"\"\"\n",
    "### Instruction:\n",
    "{}\n",
    " \n",
    "### Input:\n",
    "{}\n",
    " \n",
    "### Reference Output:\n",
    "{}\n",
    " \n",
    "### Generated Output:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "file_list = os.listdir('./generate/raw')\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join('./generate/raw', file_name)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 写入目标文件\n",
    "    with open(f'./generate/request/{file_name}.jsonl', 'w', encoding='utf-8') as out_f:\n",
    "        for idx, item in enumerate(data, 1):\n",
    "            req = {\n",
    "                \"custom_id\": f\"request-{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v4/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"glm-4-flash\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": template_user.format(\n",
    "                                item.get(\"instruction\", \"\").strip(),\n",
    "                                item.get(\"input\", \"\").strip(),\n",
    "                                item.get(\"reference_output\", \"\").strip(),\n",
    "                                item.get(\"generated_output\", \"\").strip()\n",
    "                            )\n",
    "                        }\n",
    "                    ],\n",
    "                    \"temperature\": 0.0\n",
    "                }\n",
    "            }\n",
    "            out_f.write(json.dumps(req, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54f3a5",
   "metadata": {},
   "source": [
    "## Caculate Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a192d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fkl.jsonl valid scores: 2046----{'Correctness': 3.53, 'Completeness': 3.54, 'Relevance': 4.46, 'Fluency': 4.37}\n",
      "Error in line 1206 of jskl.jsonl\n",
      "jskl.jsonl valid scores: 2045----{'Correctness': 3.55, 'Completeness': 3.57, 'Relevance': 4.49, 'Fluency': 4.4}\n",
      "none.jsonl valid scores: 2045----{'Correctness': 3.52, 'Completeness': 3.53, 'Relevance': 4.44, 'Fluency': 4.38}\n",
      "rkl.jsonl valid scores: 2046----{'Correctness': 3.53, 'Completeness': 3.55, 'Relevance': 4.46, 'Fluency': 4.38}\n",
      "seqkl.jsonl valid scores: 2046----{'Correctness': 3.51, 'Completeness': 3.55, 'Relevance': 4.43, 'Fluency': 4.38}\n",
      "teacher.jsonl valid scores: 2046----{'Correctness': 4.0, 'Completeness': 4.0, 'Relevance': 4.83, 'Fluency': 4.73}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "file_list = os.listdir('./generate/response')\n",
    "# print(file_list)\n",
    "# file_list = ['none.jsonl']\n",
    "for file in file_list:\n",
    "    file_path = os.path.join('./generate/response/', file)\n",
    "    scores = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for idx,line in enumerate(f):\n",
    "            data = json.loads(line)\n",
    "            content = data['response']['body']['choices'][0]['message']['content']\n",
    "            try:\n",
    "                content = content.strip().strip('```json').strip('```').strip()\n",
    "                obj = json.loads(content)\n",
    "            except:\n",
    "                print(f'Error in line {idx+1} of {file}')\n",
    "                continue\n",
    "\n",
    "            scores.append(obj)\n",
    "\n",
    "    dimensions = [\"Correctness\", \"Completeness\", \"Relevance\", \"Fluency\"]\n",
    "    avg_scores = {}\n",
    "    # for i,score in enumerate(scores):\n",
    "    #     try:\n",
    "    #         s = score['Correctness']\n",
    "    #     except:\n",
    "    #         print(i)\n",
    "    #         continue\n",
    "    # requestid-574 ---- none\n",
    "\n",
    "    for dim in dimensions:\n",
    "        # try:\n",
    "        #     values = [score[dim] for score in scores]\n",
    "        # except:\n",
    "        #     continue\n",
    "        values = []\n",
    "        for score in scores:\n",
    "            try:\n",
    "                values.append(score[dim])\n",
    "            except:\n",
    "                continue\n",
    "        avg_scores[dim] = round(sum(values) / len(values), 2)\n",
    "    print(f'{file} valid scores: {len(values)}----{avg_scores}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
