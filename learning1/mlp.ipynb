{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd05001",
   "metadata": {},
   "source": [
    "# Using MLP with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a393b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429f106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(300, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6be188",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2ccf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burning\\AppData\\Local\\Temp\\ipykernel_18688\\1877844416.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "def review_to_words( review, remove_stopwords=False ):\n",
    "\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    if remove_stopwords:    \n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words\n",
    "\n",
    "train_data = pd.read_csv(\"./data/labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "        \n",
    "clean_train_reviews = []\n",
    "for revuew in train_data[\"review\"]:\n",
    "    clean_train_reviews.append(review_to_words(revuew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82de6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(clean_train_reviews) == train_data[\"review\"].size, \"Error: Cleaning training set reviews failed\"\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v = Word2Vec.load('./data/300features_40minwords_10context')\n",
    "\n",
    "def review2vec(model, review):\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    vectors = [model.wv[word] for word in review if word in index2word_set]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n",
    "\n",
    "X = np.array([review2vec(w2v, review) for review in clean_train_reviews])\n",
    "Y = np.array(train_data[\"sentiment\"])\n",
    "\n",
    "\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "Y_tensor = torch.FloatTensor(Y).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0a834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25000, 300]), torch.Size([25000, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape, Y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0423307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d9e55",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9fa1a",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/30\n",
      "Train Loss: 0.4508 | Val Loss: 0.3332 | Val Acc: 0.8610\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n",
      "Train Loss: 0.3425 | Val Loss: 0.3151 | Val Acc: 0.8658\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n",
      "Train Loss: 0.3337 | Val Loss: 0.3105 | Val Acc: 0.8688\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n",
      "Train Loss: 0.3260 | Val Loss: 0.3052 | Val Acc: 0.8698\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n",
      "Train Loss: 0.3219 | Val Loss: 0.3034 | Val Acc: 0.8708\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3195 | Val Loss: 0.2979 | Val Acc: 0.8742\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n",
      "Train Loss: 0.3171 | Val Loss: 0.2984 | Val Acc: 0.8736\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n",
      "Train Loss: 0.3154 | Val Loss: 0.2955 | Val Acc: 0.8764\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n",
      "Train Loss: 0.3127 | Val Loss: 0.3113 | Val Acc: 0.8656\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n",
      "Train Loss: 0.3112 | Val Loss: 0.2944 | Val Acc: 0.8748\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n",
      "Train Loss: 0.2998 | Val Loss: 0.2891 | Val Acc: 0.8782\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n",
      "Train Loss: 0.2965 | Val Loss: 0.2901 | Val Acc: 0.8756\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n",
      "Train Loss: 0.2952 | Val Loss: 0.2913 | Val Acc: 0.8764\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n",
      "Train Loss: 0.2938 | Val Loss: 0.2884 | Val Acc: 0.8802\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n",
      "Train Loss: 0.2942 | Val Loss: 0.2876 | Val Acc: 0.8784\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n",
      "Train Loss: 0.2941 | Val Loss: 0.2871 | Val Acc: 0.8796\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n",
      "Train Loss: 0.2922 | Val Loss: 0.2876 | Val Acc: 0.8792\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n",
      "Train Loss: 0.2924 | Val Loss: 0.2889 | Val Acc: 0.8794\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2904 | Val Loss: 0.2881 | Val Acc: 0.8812\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n",
      "Train Loss: 0.2890 | Val Loss: 0.2866 | Val Acc: 0.8804\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n",
      "Train Loss: 0.2882 | Val Loss: 0.2862 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2880 | Val Loss: 0.2861 | Val Acc: 0.8824\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2870 | Val Loss: 0.2861 | Val Acc: 0.8818\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2865 | Val Loss: 0.2860 | Val Acc: 0.8824\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2872 | Val Loss: 0.2859 | Val Acc: 0.8828\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2862 | Val Loss: 0.2860 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2856 | Val Loss: 0.2865 | Val Acc: 0.8794\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2860 | Val Loss: 0.2859 | Val Acc: 0.8830\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2840 | Val Loss: 0.2858 | Val Acc: 0.8806\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n",
      "Train Loss: 0.2856 | Val Loss: 0.2858 | Val Acc: 0.8828\n",
      "--------------------------------------------------\n",
      "Fold 2\n",
      "Epoch 1/30\n",
      "Train Loss: 0.4525 | Val Loss: 0.3255 | Val Acc: 0.8624\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n",
      "Train Loss: 0.3433 | Val Loss: 0.3181 | Val Acc: 0.8640\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n",
      "Train Loss: 0.3307 | Val Loss: 0.3078 | Val Acc: 0.8674\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n",
      "Train Loss: 0.3248 | Val Loss: 0.3067 | Val Acc: 0.8710\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n",
      "Train Loss: 0.3222 | Val Loss: 0.3063 | Val Acc: 0.8708\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3181 | Val Loss: 0.2983 | Val Acc: 0.8740\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n",
      "Train Loss: 0.3135 | Val Loss: 0.2988 | Val Acc: 0.8720\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n",
      "Train Loss: 0.3145 | Val Loss: 0.3076 | Val Acc: 0.8658\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n",
      "Train Loss: 0.3137 | Val Loss: 0.2974 | Val Acc: 0.8746\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n",
      "Train Loss: 0.3092 | Val Loss: 0.2939 | Val Acc: 0.8718\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n",
      "Train Loss: 0.3000 | Val Loss: 0.2936 | Val Acc: 0.8760\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n",
      "Train Loss: 0.2979 | Val Loss: 0.2930 | Val Acc: 0.8762\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n",
      "Train Loss: 0.2946 | Val Loss: 0.2932 | Val Acc: 0.8758\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n",
      "Train Loss: 0.2942 | Val Loss: 0.2948 | Val Acc: 0.8764\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n",
      "Train Loss: 0.2937 | Val Loss: 0.2917 | Val Acc: 0.8778\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n",
      "Train Loss: 0.2917 | Val Loss: 0.2916 | Val Acc: 0.8776\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n",
      "Train Loss: 0.2915 | Val Loss: 0.2905 | Val Acc: 0.8774\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n",
      "Train Loss: 0.2910 | Val Loss: 0.2924 | Val Acc: 0.8776\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2908 | Val Loss: 0.2941 | Val Acc: 0.8772\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n",
      "Train Loss: 0.2902 | Val Loss: 0.2905 | Val Acc: 0.8776\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n",
      "Train Loss: 0.2875 | Val Loss: 0.2903 | Val Acc: 0.8778\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2878 | Val Loss: 0.2904 | Val Acc: 0.8770\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2865 | Val Loss: 0.2907 | Val Acc: 0.8770\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2861 | Val Loss: 0.2903 | Val Acc: 0.8776\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2841 | Val Loss: 0.2906 | Val Acc: 0.8772\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2857 | Val Loss: 0.2905 | Val Acc: 0.8774\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2855 | Val Loss: 0.2904 | Val Acc: 0.8772\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2857 | Val Loss: 0.2903 | Val Acc: 0.8774\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2851 | Val Loss: 0.2904 | Val Acc: 0.8786\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n",
      "Train Loss: 0.2849 | Val Loss: 0.2903 | Val Acc: 0.8774\n",
      "--------------------------------------------------\n",
      "Fold 3\n",
      "Epoch 1/30\n",
      "Train Loss: 0.4595 | Val Loss: 0.3288 | Val Acc: 0.8654\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n",
      "Train Loss: 0.3431 | Val Loss: 0.3108 | Val Acc: 0.8728\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n",
      "Train Loss: 0.3328 | Val Loss: 0.3024 | Val Acc: 0.8770\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n",
      "Train Loss: 0.3254 | Val Loss: 0.2995 | Val Acc: 0.8798\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n",
      "Train Loss: 0.3213 | Val Loss: 0.3116 | Val Acc: 0.8734\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3203 | Val Loss: 0.3053 | Val Acc: 0.8770\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n",
      "Train Loss: 0.3150 | Val Loss: 0.2967 | Val Acc: 0.8794\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n",
      "Train Loss: 0.3153 | Val Loss: 0.2981 | Val Acc: 0.8752\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n",
      "Train Loss: 0.3127 | Val Loss: 0.2933 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n",
      "Train Loss: 0.3089 | Val Loss: 0.2973 | Val Acc: 0.8758\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n",
      "Train Loss: 0.3047 | Val Loss: 0.2904 | Val Acc: 0.8822\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n",
      "Train Loss: 0.2970 | Val Loss: 0.2897 | Val Acc: 0.8832\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n",
      "Train Loss: 0.2963 | Val Loss: 0.2913 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n",
      "Train Loss: 0.2958 | Val Loss: 0.2915 | Val Acc: 0.8822\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n",
      "Train Loss: 0.2936 | Val Loss: 0.2893 | Val Acc: 0.8828\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n",
      "Train Loss: 0.2939 | Val Loss: 0.2898 | Val Acc: 0.8818\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n",
      "Train Loss: 0.2913 | Val Loss: 0.2899 | Val Acc: 0.8830\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n",
      "Train Loss: 0.2931 | Val Loss: 0.2889 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2920 | Val Loss: 0.2894 | Val Acc: 0.8826\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n",
      "Train Loss: 0.2914 | Val Loss: 0.2887 | Val Acc: 0.8808\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n",
      "Train Loss: 0.2875 | Val Loss: 0.2882 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2866 | Val Loss: 0.2883 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2872 | Val Loss: 0.2883 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2884 | Val Loss: 0.2883 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2882 | Val Loss: 0.2885 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2865 | Val Loss: 0.2882 | Val Acc: 0.8826\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2865 | Val Loss: 0.2883 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2868 | Val Loss: 0.2883 | Val Acc: 0.8808\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2857 | Val Loss: 0.2882 | Val Acc: 0.8816\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n",
      "Train Loss: 0.2855 | Val Loss: 0.2882 | Val Acc: 0.8812\n",
      "--------------------------------------------------\n",
      "Fold 4\n",
      "Epoch 1/30\n",
      "Train Loss: 0.4507 | Val Loss: 0.3342 | Val Acc: 0.8684\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n",
      "Train Loss: 0.3400 | Val Loss: 0.3208 | Val Acc: 0.8714\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n",
      "Train Loss: 0.3300 | Val Loss: 0.3181 | Val Acc: 0.8724\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n",
      "Train Loss: 0.3241 | Val Loss: 0.3107 | Val Acc: 0.8752\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n",
      "Train Loss: 0.3177 | Val Loss: 0.3092 | Val Acc: 0.8750\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3169 | Val Loss: 0.3067 | Val Acc: 0.8766\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n",
      "Train Loss: 0.3141 | Val Loss: 0.3062 | Val Acc: 0.8772\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n",
      "Train Loss: 0.3134 | Val Loss: 0.3171 | Val Acc: 0.8684\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n",
      "Train Loss: 0.3115 | Val Loss: 0.3082 | Val Acc: 0.8750\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n",
      "Train Loss: 0.3080 | Val Loss: 0.3130 | Val Acc: 0.8708\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n",
      "Train Loss: 0.2976 | Val Loss: 0.3065 | Val Acc: 0.8754\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n",
      "Train Loss: 0.2951 | Val Loss: 0.3008 | Val Acc: 0.8786\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n",
      "Train Loss: 0.2945 | Val Loss: 0.3009 | Val Acc: 0.8798\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n",
      "Train Loss: 0.2917 | Val Loss: 0.3001 | Val Acc: 0.8782\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n",
      "Train Loss: 0.2907 | Val Loss: 0.3002 | Val Acc: 0.8792\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n",
      "Train Loss: 0.2901 | Val Loss: 0.2999 | Val Acc: 0.8784\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n",
      "Train Loss: 0.2911 | Val Loss: 0.3034 | Val Acc: 0.8752\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n",
      "Train Loss: 0.2882 | Val Loss: 0.3027 | Val Acc: 0.8764\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2883 | Val Loss: 0.2999 | Val Acc: 0.8810\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n",
      "Train Loss: 0.2865 | Val Loss: 0.3012 | Val Acc: 0.8786\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n",
      "Train Loss: 0.2863 | Val Loss: 0.2992 | Val Acc: 0.8794\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2845 | Val Loss: 0.2993 | Val Acc: 0.8790\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2820 | Val Loss: 0.2985 | Val Acc: 0.8814\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2838 | Val Loss: 0.2982 | Val Acc: 0.8820\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2840 | Val Loss: 0.2987 | Val Acc: 0.8806\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2839 | Val Loss: 0.3002 | Val Acc: 0.8784\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2833 | Val Loss: 0.2983 | Val Acc: 0.8812\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2830 | Val Loss: 0.2984 | Val Acc: 0.8810\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2830 | Val Loss: 0.2981 | Val Acc: 0.8816\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n",
      "Train Loss: 0.2825 | Val Loss: 0.2989 | Val Acc: 0.8790\n",
      "--------------------------------------------------\n",
      "Fold 5\n",
      "Epoch 1/30\n",
      "Train Loss: 0.4513 | Val Loss: 0.3604 | Val Acc: 0.8470\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n",
      "Train Loss: 0.3347 | Val Loss: 0.3448 | Val Acc: 0.8534\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n",
      "Train Loss: 0.3256 | Val Loss: 0.3351 | Val Acc: 0.8578\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n",
      "Train Loss: 0.3189 | Val Loss: 0.3429 | Val Acc: 0.8540\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n",
      "Train Loss: 0.3162 | Val Loss: 0.3431 | Val Acc: 0.8534\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n",
      "Train Loss: 0.3113 | Val Loss: 0.3318 | Val Acc: 0.8580\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n",
      "Train Loss: 0.3086 | Val Loss: 0.3257 | Val Acc: 0.8624\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n",
      "Train Loss: 0.3068 | Val Loss: 0.3407 | Val Acc: 0.8558\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n",
      "Train Loss: 0.3044 | Val Loss: 0.3261 | Val Acc: 0.8616\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n",
      "Train Loss: 0.3019 | Val Loss: 0.3332 | Val Acc: 0.8610\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n",
      "Train Loss: 0.2912 | Val Loss: 0.3263 | Val Acc: 0.8628\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n",
      "Train Loss: 0.2892 | Val Loss: 0.3253 | Val Acc: 0.8626\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n",
      "Train Loss: 0.2875 | Val Loss: 0.3234 | Val Acc: 0.8640\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n",
      "Train Loss: 0.2851 | Val Loss: 0.3261 | Val Acc: 0.8626\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n",
      "Train Loss: 0.2850 | Val Loss: 0.3297 | Val Acc: 0.8616\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n",
      "Train Loss: 0.2842 | Val Loss: 0.3256 | Val Acc: 0.8636\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n",
      "Train Loss: 0.2823 | Val Loss: 0.3280 | Val Acc: 0.8648\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n",
      "Train Loss: 0.2841 | Val Loss: 0.3315 | Val Acc: 0.8630\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n",
      "Train Loss: 0.2815 | Val Loss: 0.3254 | Val Acc: 0.8640\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n",
      "Train Loss: 0.2821 | Val Loss: 0.3272 | Val Acc: 0.8652\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n",
      "Train Loss: 0.2792 | Val Loss: 0.3265 | Val Acc: 0.8662\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2783 | Val Loss: 0.3262 | Val Acc: 0.8648\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2787 | Val Loss: 0.3254 | Val Acc: 0.8656\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2756 | Val Loss: 0.3273 | Val Acc: 0.8644\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2767 | Val Loss: 0.3260 | Val Acc: 0.8666\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2772 | Val Loss: 0.3244 | Val Acc: 0.8656\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2764 | Val Loss: 0.3263 | Val Acc: 0.8656\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2774 | Val Loss: 0.3252 | Val Acc: 0.8664\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2762 | Val Loss: 0.3248 | Val Acc: 0.8668\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n",
      "Train Loss: 0.2756 | Val Loss: 0.3252 | Val Acc: 0.8666\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fold_train_losses, fold_val_losses, fold_val_accs = [], [], []\n",
    "\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = MLP().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "    loss_fc = nn.BCELoss()\n",
    "    \n",
    "    train_losses, va_losses, va_acc = [], [], []\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fc(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fc(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        va_losses.append(val_loss)\n",
    "        va_acc.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/30\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f\"./data/mlp_model_fold{fold+1}_best.pth\")  # 保存当前折最优\n",
    "    \n",
    "    fold_train_losses.append(train_losses)\n",
    "    fold_val_losses.append(va_losses)\n",
    "    fold_val_accs.append(va_acc)\n",
    "\n",
    "    max_acc = max(va_acc)\n",
    "    if max_acc > best_val_acc:\n",
    "        best_val_acc = max_acc\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "torch.save(best_model_state, f\"./data/best_mlp_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.6, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burning\\AppData\\Local\\Temp\\ipykernel_18688\\1877844416.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(review).get_text()\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"./data/testData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "model = MLP().to(device)\n",
    "model.load_state_dict(torch.load(\"./data/best_mlp_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "print(model)\n",
    "with torch.no_grad():\n",
    "    clean_test_reviews = []\n",
    "    for review in test[\"review\"]:\n",
    "        clean_test_reviews.append(review_to_words(review))\n",
    "\n",
    "    Xtest = np.array([review2vec(w2v, review) for review in clean_test_reviews])\n",
    "\n",
    "    Xtest_tensor = torch.FloatTensor(Xtest)\n",
    "\n",
    "    output = model(Xtest_tensor)\n",
    "    result = (output > 0.5).cpu().numpy().astype(int).flatten()\n",
    "    \n",
    "    output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "    output.to_csv( \"./data/mlp.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
